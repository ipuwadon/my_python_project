# PySpark ETL Pipeline (Local VSCode Project)

This project is a modular ETL pipeline built with PySpark and SQLite, designed for local development using VSCode. It includes CI/CD automation, clean architecture, and unit testing.

## Tech Stack
- Python
- PySpark
- SQLite
- Git + GitHub Actions
- pytest + chispa
- flake8 + black

## Project Structure
my_data_pipeline_project/ 
my_data_pipeline_project/
â”œâ”€â”€ ğŸ“ scripts/                  # Core ETL logic (modular Python scripts)
â”‚   â”œâ”€â”€ extract.py              # Load data from CSV, API, or other sources
â”‚   â”œâ”€â”€ transform.py            # Clean and transform data using PySpark
â”‚   â”œâ”€â”€ load.py                 # Save transformed data into SQLite
â”‚   â””â”€â”€ main.py                 # Orchestrates the ETL pipeline (calls extract â†’ transform â†’ load)
â”‚
â”œâ”€â”€ ğŸ“ data/                     # Input and output data files
â”‚   â””â”€â”€ sample_data.csv         # Example input dataset
â”‚
â”œâ”€â”€ ğŸ“ tests/                    # Unit tests for pipeline components
â”‚   â””â”€â”€ test_transform.py       # Tests for PySpark transformations using `chispa`
â”‚
â”œâ”€â”€ ğŸ“ .github/                  # GitHub Actions CI/CD configuration
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ ci.yml              # Workflow for testing, linting, and formatting
â”‚
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ README.md                   # Project overview and instructions



